{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC478 Machine Learning - Fall 2020 \n",
    "\n",
    "## Instructor: Fereydoon Vafaei\n",
    "\n",
    "### <font color=\"blue\">Assignment-1: Binary Classification, Linear Regression and Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Type your name and ID here* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you've learned about the basics and fundamental concepts in Machine Learning such as supervised learning (e.g. classification and regression) vs unsupervised learning (e.g. clustering), overfitting, and model evaluation. You learned that two of the most common approaches in supervised learning are regression and classification. In this assignment, you are going to prcatice what you've learned so far by building ML models and applying them on data.\n",
    "\n",
    "<b>Very Important Note:</b> Read ALL the instructions in this notebook very carefully. Careless reading and skipping lines would be a major source of making mistakes and losing points in your first assignment! Also notice that this assignment has three parts and includes multiple steps and questions. You're strongly recommended to get started early and plan to finish well before the due. Technical problems or other issues/questions on the due date or just a day before would NOT be accepted as an excuse to delay your submission. As stated in the policy, ALL assignments are indvidual work and students are strictly prohibited from collaboration on assignments. Students are responsible to debug the code and resolve any errors that may arise. Students should NOT share any answer, solution, or code/snippet in Piazza. Violations of these policies would be penalized accordingly.\n",
    "\n",
    "Pedagogically, this assignment will help you:\n",
    "- better understand the concepts you learned and how to use ML models in practice. \n",
    "- practice your Python skills\n",
    "- pratice reading documentation. This is a very important skill in AI/ML/Data Science collaborative environments and teams.\n",
    "\n",
    "So, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I - Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification means you are classifying only two classes/labels. You are going to build a binary classifier that can classify breats cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is downloading the [Indian Liver Patient Records](https://www.kaggle.com/uciml/indian-liver-patient-records) dataset. Read the feature specifications in Kaggle page to learn more about the data. The target label is `Dataset` which has two labels {1,2}. You should save the data in the same working directory as your notebook. Next, you should load the data using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Male</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65  Female              0.7               0.1                   187   \n",
       "1   62    Male             10.9               5.5                   699   \n",
       "2   62    Male              7.3               4.1                   490   \n",
       "3   58    Male              1.0               0.4                   182   \n",
       "4   72    Male              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        1  \n",
       "1      3.2                        0.74        1  \n",
       "2      3.3                        0.89        1  \n",
       "3      3.4                        1.00        1  \n",
       "4      2.4                        0.40        1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset using pd\n",
    "liver_data = pd.read_csv('indian_liver_patient.csv')\n",
    "\n",
    "# Show the first five rows\n",
    "liver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 11)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 416 patients and 167 non-patients\n",
    "liver_data.loc[liver_data['Dataset'] == 2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's see what the type of `data` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(liver_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` is a data structure to contain datasets in pandas. Read pandas documentation to learn more about it [here](https://pandas.pydata.org/docs/user_guide/10min.html#min) and [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html). Since this is a binary classification (supervised learning) ML model, you have both the features and the labels for training and testing, and everything has been stored in `liver_data` DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [scikit-learn LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) module, change the `Gender` categorical values from {Female,Male} to {0,1} and the `Dataset` target label values from {1,2} to {0,1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(583, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65       0              0.7               0.1                   187   \n",
       "1   62       1             10.9               5.5                   699   \n",
       "2   62       1              7.3               4.1                   490   \n",
       "3   58       1              1.0               0.4                   182   \n",
       "4   72       1              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  Dataset  \n",
       "0      3.3                        0.90        0  \n",
       "1      3.2                        0.74        0  \n",
       "2      3.3                        0.89        0  \n",
       "3      3.4                        1.00        0  \n",
       "4      2.4                        0.40        0  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical Gender values {Female, Male} to {0,1} and the Dataset labels {1,2} to {1,0}\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "liver_data['Gender'] = labelencoder.fit_transform(liver_data['Gender'])\n",
    "liver_data['Dataset'] = labelencoder.fit_transform(liver_data['Dataset'])\n",
    "print(liver_data.shape)\n",
    "liver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_data['Dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 11)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_data.loc[liver_data['Dataset'] == 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">You should always check if your dataset has `NA` or `Null` values and decide about it, usually drop `NA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 11)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop all NAs\n",
    "liver_data.dropna(inplace=True)\n",
    "liver_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           0\n",
       "Gender                        0\n",
       "Total_Bilirubin               0\n",
       "Direct_Bilirubin              0\n",
       "Alkaline_Phosphotase          0\n",
       "Alamine_Aminotransferase      0\n",
       "Aspartate_Aminotransferase    0\n",
       "Total_Protiens                0\n",
       "Albumin                       0\n",
       "Albumin_and_Globulin_Ratio    0\n",
       "Dataset                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_data.isnull().sum()\n",
    "liver_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, you can extract features and labels from `liver_data`. Your classifier should attempt to predict `Dataset` binary classes so that is your target/label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data to feature vector X and label vector y\n",
    "X = liver_data.drop(['Dataset'], axis=1)\n",
    "y = liver_data['Dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (579, 10)\n",
      "Labels shape:  (579,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features shape: \", X.shape)\n",
    "print(\"Labels shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your `X` dataframe now only contains features, hence has 10 columns whereas `y` has now become a 1D vector containing labels only. Notice that `y` has 579 labels equal to the number of data records in the feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Total_Bilirubin</th>\n",
       "      <th>Direct_Bilirubin</th>\n",
       "      <th>Alkaline_Phosphotase</th>\n",
       "      <th>Alamine_Aminotransferase</th>\n",
       "      <th>Aspartate_Aminotransferase</th>\n",
       "      <th>Total_Protiens</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Albumin_and_Globulin_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>699</td>\n",
       "      <td>64</td>\n",
       "      <td>100</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>490</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>182</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Gender  Total_Bilirubin  Direct_Bilirubin  Alkaline_Phosphotase  \\\n",
       "0   65       0              0.7               0.1                   187   \n",
       "1   62       1             10.9               5.5                   699   \n",
       "2   62       1              7.3               4.1                   490   \n",
       "3   58       1              1.0               0.4                   182   \n",
       "4   72       1              3.9               2.0                   195   \n",
       "\n",
       "   Alamine_Aminotransferase  Aspartate_Aminotransferase  Total_Protiens  \\\n",
       "0                        16                          18             6.8   \n",
       "1                        64                         100             7.5   \n",
       "2                        60                          68             7.0   \n",
       "3                        14                          20             6.8   \n",
       "4                        27                          59             7.3   \n",
       "\n",
       "   Albumin  Albumin_and_Globulin_Ratio  \n",
       "0      3.3                        0.90  \n",
       "1      3.2                        0.74  \n",
       "2      3.3                        0.89  \n",
       "3      3.4                        1.00  \n",
       "4      2.4                        0.40  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X should no longer contain the Dataset column which is target/label column - i.e. the column to be predicted\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y should only contain class labels - Dataset target/label column\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When you have multiple features with different scales/ranges, you should consider standardizing them. There are different ways to standardize and to normalize the feature vector. One way is using scikit-learn modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the lectures, the data for supervised learning (both classification and regression) is split into training set and test set. We do this by importing another module from scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can split the data. The split ratio we are going to choose is 0.75 for training and 0.25 for testing, but we only need to specify one of them `test_size` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (434, 10)\n",
      "y_train shape:  (434,)\n",
      "X_test shape:  (145, 10)\n",
      "y_test shape:  (145,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of X_train, X_test, y_train, y_test\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we can now choose which classifier from the built-in classifiers in sklearn we want to use. We are going to use two classifiers that we've seen in the lectures so far: Stochastic Gradient Descent Classifier and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the following cell. You may want to consult with the textbook code snippets. Notice that we use [`.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.fit) method for training and [`.predict()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.predict) method for making predictions (testing). Click on the methods and read their documentation.\n",
    "\n",
    "Enter your code in the blocks that start with `### START CODE HERE ###` and replace the ellipsis `...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "\n",
    "# Create a SGDClassifier with random_state=0\n",
    "sgd_clf = ...\n",
    "\n",
    "# Fit sgd_clf model on training set\n",
    "...\n",
    "\n",
    "# Create a LogisticRegression classifier with solver='liblinear'\n",
    "log_reg_clf = ...\n",
    "\n",
    "# Fit log_reg_clf on training set\n",
    "...\n",
    "\n",
    "# Create a RandomForestClassifier with max_depth=2\n",
    "rf_clf = ...\n",
    "\n",
    "# Fit log_reg_clf on training set\n",
    "...\n",
    "### END CODING HERE ###\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, make predictions on testing set and store the results\n",
    "\n",
    "### START CODING HERE ###\n",
    "y_pred_sgd = ...\n",
    "y_pred_log_reg = ...\n",
    "y_pred_rf = ...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_pred_sgd), type(y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred_sgd.shape == y_pred_log_reg.shape, \"Prediction shapes don't match!\"\n",
    "print(y_pred_sgd.shape)\n",
    "print(y_pred_log_reg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, evaluate how your classifiers perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "\n",
    "# Import the necessary modules from sklearn for accuracy_score, precision_score and recall_score \n",
    "...\n",
    "\n",
    "# Compute the accuracy, precision and recall for SGD\n",
    "acc_sgd = ...\n",
    "precision_sgd = ...\n",
    "recall_sgd = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "# Print the accuracy, precision and recall for SGD \n",
    "print(\"SGD Accuracy: \", acc_sgd)\n",
    "print(\"SGD Precision: \", precision_sgd)\n",
    "print(\"SGD Recall: \", recall_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, make similar computations for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "\n",
    "# Compute the accuracy, precision and recall for LogReg\n",
    "acc_log_reg = ...\n",
    "precision_log_reg = ...\n",
    "recall_log_reg = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "# Print the accuracy, precision and recall for LogReg\n",
    "print(\"LogReg Accuracy: \", acc_log_reg)\n",
    "print(\"LogReg Precision: \", precision_log_reg)\n",
    "print(\"LogReg Recall: \", recall_log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, make similar computations for Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "\n",
    "# Compute the accuracy, precision and recall for RF\n",
    "acc_rf = ...\n",
    "precision_rf = ...\n",
    "recall_rf = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "# Print the accuracy, precision and recall for RF\n",
    "print(\"RF Accuracy: \", acc_rf)\n",
    "print(\"RF Precision: \", precision_rf)\n",
    "print(\"RF Recall: \", recall_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, the following cells show how you can plot ROC curve of logistic regression classifier using `fpr`, `tpr`, and `threshold` returned by [`metrics.roc_curve`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) and class probabilities using [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) method of [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class probabilities, fpr, tpr and threshold for Logistic Regression.\n",
    "import sklearn.metrics as metrics\n",
    "log_reg_probs = log_reg_clf.predict_proba(X_test)\n",
    "log_reg_preds = log_reg_probs[:,1]\n",
    "log_reg_fpr, log_reg_tpr, log_reg_threshold = metrics.roc_curve(y_test, log_reg_preds)\n",
    "log_reg_roc_auc = metrics.auc(log_reg_fpr, log_reg_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve for logistic regression classifier\n",
    "plt.title('ROC')\n",
    "plt.plot(log_reg_fpr, log_reg_tpr, 'b', label = 'AUC_Log_Reg = %0.2f' % log_reg_roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you should plot ROC curves of ALL THREE classifiers in ONE PLOT. Notice that some classifiers like SGD don't have `predict_proba` method, and in that case you can use [`decision_function`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier.decision_function) method to get the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC for ALL THREE classifiers with different colors in one plot,\n",
    "# and with AUC scores shown on the 'lower right' of the plot.\n",
    "\n",
    "# Write as many number of lines of code as needed.\n",
    "\n",
    "# Hint1: You may use LogisticRegression ROC curve as a reference for writing your code.\n",
    "# Hint2: sgd with 'hinge' loss doesn't have predict_proba method,\n",
    "# instead, you should directly use decision_function method to compute sgd_preds\n",
    "\n",
    "### START CODING HERE ###\n",
    "# Write as many number of lines of code as needed here.\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q1 [2 points] - What is the data type of `y_pred_sgd` and `y_pred_log_reg` and what are their shapes? Explain why you get such a shape for predictions. \n",
    "\n",
    "\n",
    "- Q2 [1 points]- Which classifier has the highest recall?\n",
    "\n",
    "\n",
    "- Q3 [2 points]- Looking at ROC curves of Logistic Regression and SGD, and without seeing AUC scores, how would you determine which classifier has a better performance?\n",
    "\n",
    "<font color=red>Enter your answers in the following markdown cell.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your answers to Part I questions go HERE - below this line:\n",
    "\n",
    "========================================================\n",
    "\n",
    "\n",
    "YOUR Answers:\n",
    "\n",
    "- Q1: \n",
    "\n",
    "\n",
    "- Q2:  \n",
    "\n",
    "\n",
    "- Q3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II - Linear Regression Using Closed-Form Solution (Normal Equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part II, you're going to generate some data and then use closed-form solution for linear regression to fit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data points based on the following linear equation added by [the noise with “standard normal” distribution](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randn.html). You may refer to the slides/textbook code snippets.\n",
    "\n",
    "$$y = 5 + 4X + Gaussian Noise$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2 * np.random.rand(100, 1)\n",
    "\n",
    "### START CODING HERE ###\n",
    "# Compute y based on the linear equation given above and add random gaussian noise\n",
    "y = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# add x0 = 1 to each instance using np.c_\n",
    "X_b = ...\n",
    "\n",
    "# Compute theta_best using normal equation\n",
    "theta_best = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])\n",
    "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
    "X_new_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "# Make predictions on new data by computing the dot product of X_new_b and theta_best\n",
    "y_predict = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_new, y_predict, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([0, 2, 0, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III - Regression Using Least Mean Square and RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part III, you will implement three functions to build and use regression models: `train`, `use`, and `rmse` and then you apply them to some weather data.\n",
    "\n",
    "Here are the specifications for these functions, which you must satisfy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model = train(X, T, learning_rate, n_epochs, verbose)`\n",
    "* `X`: is an $N$ x $D$ matrix of input data samples, one per row. $N$ is the number of samples and $D$ is the number of variable values in\n",
    "each sample.\n",
    "* `T`: is an $N$ x $K$ matrix of desired target values for each sample.  $K$ is the number of output values you want to predict for each sample.\n",
    "* `learning_rate`: is a scalar that controls the step size of each update to the weight values.\n",
    "* `n_epochs`: is the number of epochs, or passes, through all $N$ samples, to take while updating the weight values.\n",
    "* `verbose`: is True or False (default value) to control whether or not occasional text is printed to show the training progress.\n",
    "* `model`: is the returned value, which must be a dictionary with the keys `'w'`, `'Xmeans'`, `'Xstds'`, `'Tmeans'` and `'Tstds'`.\n",
    "\n",
    "`Y = use(X, model)`\n",
    "* `X`: is an $N$ x $D$ matrix of input data samples, one per row, for which you want to predict the target values.\n",
    "* `model`: is the dictionary returned by `train`.\n",
    "* `Y`: is the returned $N$ x $K$ matrix of predicted values, one for each sample in `X`.\n",
    "\n",
    "`result = rmse(Y, T)`\n",
    "* `Y`: is an $N$ x $K$ matrix of predictions produced by `use`.\n",
    "* `T`: is the $N$ x $K$ matrix of target values.\n",
    "* `result`: is a scalar calculated as the square root of the mean of the squared differences between each sample (row) in `Y` and `T`.\n",
    "\n",
    "<b>Hints:</b>\n",
    "- Remember from regression performance measure that RMSE equation is:\n",
    "\n",
    "$\n",
    "\\text{RMSE}(\\mathbf{X}, h) = \\sqrt{\\frac{1}{m}\\sum\\limits_{i=1}^{m}\\left(h(\\mathbf{x}^{(i)}) - y^{(i)}\\right)^2}\n",
    "$\n",
    "\n",
    "where $h(\\mathbf{x}^{(i)})$ is your prediction versus $y^{(i)}$ target values. Notice that you will implement rmse twice, once in `train` function, and once as a separate function named `rmse`. In the `rmse` function when you work with vectorized form of Y and T, you can simply subtract and square them but you need to get the mean and the square root as well.<br>\n",
    "\n",
    "- Also notice that in Python, you may use `@` as matrix multiplication operator between vectors. That is a simpler notation came in recent versions of Python 3.5+ as an alternative for [`numpy.matmul`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html). This would be used between two matrices whereas when you multiply a single scalar to a matrix such as `learning_rate` multiplied by a matrix, you may use `*` operator.\n",
    "\n",
    "\n",
    "- During the training and in each iteration, weights would be updated as the following: \n",
    "`w = w + learning_rate * X[n:n + 1, :].T * error`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "def train(X, T, learning_rate, n_epochs, verbose=False):\n",
    "\n",
    "    # Calculate means and standard deviations of each column in X and T\n",
    "    Xmeans = ...\n",
    "    Xstds = ...\n",
    "    Tmeans = ...\n",
    "    Tstds = ...\n",
    "    \n",
    "    # Use the means and standard deviations to standardize X and T\n",
    "    X = ...\n",
    "    T = ...\n",
    "\n",
    "    # Insert the column of constant 1's as a new initial column in X\n",
    "    X = ...\n",
    "    \n",
    "    # Initialize weights to be a numpy array of the correct shape and all zero values.\n",
    "    n_samples, n_inputs = ...\n",
    "    n_outputs = ...\n",
    "    w = ...\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sqerror_sum = 0\n",
    "\n",
    "        for n in range(n_samples):\n",
    "\n",
    "            # Use current weight values to predict output for sample n (provided here), then\n",
    "            # calculate the error, and\n",
    "            # update the weight values.\n",
    "            y = X[n:n + 1, :] @ w      # predicted value y for sample n\n",
    "            error = ...\n",
    "            w += ...\n",
    "            \n",
    "            # Add the squared error to sqerror_sum\n",
    "            sqerror_sum += ...\n",
    "            \n",
    "        if verbose and (n_epochs < 11 or (epoch + 1) % (n_epochs // 10) == 0):\n",
    "            # Compute RMSE\n",
    "            rmse = ...\n",
    "            rmse = rmse[0, 0]  # because rmse is 1x1 matrix\n",
    "            print(f'Epoch {epoch + 1} RMSE {rmse:.2f}')\n",
    "\n",
    "    return {'w': w, 'Xmeans': Xmeans, 'Xstds': Xstds,\n",
    "            'Tmeans': Tmeans, 'Tstds': Tstds}\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ###\n",
    "def use(X, model):\n",
    "    # Standardize X using Xmeans and Xstds in model\n",
    "    X = ...\n",
    "    # Insert the column of constant 1's as a new initial column in X\n",
    "    X = ...\n",
    "    # Predict output values using weights in model\n",
    "    Y = ...\n",
    "    # Unstandardize the predicted output values using Tmeans and Tstds in model\n",
    "    Y = ...\n",
    "    # Return the unstandardized output values\n",
    "    ...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "def rmse(A, B):\n",
    "    ...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(0, 100).reshape(-1, 1)  # make X a 100 x 1 matrix\n",
    "T = 0.5 + 0.3 * X + 0.005 * (X - 50) ** 2\n",
    "plt.plot(X, T, '.')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('T');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(X, T, 0.01, 50, verbose=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = use(X, model)\n",
    "plt.plot(T, '.', label='T')\n",
    "plt.plot(Y, '.', label='Y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rmse(Y, T)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y[:, 0], T[:, 0], 'o')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "a = max(min(Y[:, 0]), min(T[:, 0]))\n",
    "b = min(max(Y[:, 0]), max(T[:, 0]))\n",
    "plt.plot([a, b], [a, b], 'r', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 RMSE 0.46\n",
      "Epoch 200 RMSE 0.24\n",
      "Epoch 300 RMSE 0.15\n",
      "Epoch 400 RMSE 0.13\n",
      "Epoch 500 RMSE 0.13\n",
      "Epoch 600 RMSE 0.12\n",
      "Epoch 700 RMSE 0.12\n",
      "Epoch 800 RMSE 0.12\n",
      "Epoch 900 RMSE 0.12\n",
      "Epoch 1000 RMSE 0.12\n"
     ]
    }
   ],
   "source": [
    "# Just for testing if your implementation is correct\n",
    "# You should get the provided correct output\n",
    "X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
    "T = (X - 5) * 0.05 + 0.002 * (X - 8)**2\n",
    "model = train(X, T, 0.001, 1000, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your functions are working, we can apply them to some real data. You will use data\n",
    "from  [Colorado State University's CoAgMet Station Daily Data Access](http://coagmet.colostate.edu/cgi-bin/dailydata_form.pl).\n",
    "\n",
    "You can download the data file directly from the ML course GitHub repo [here](https://github.com/fereydoonvafaei/CMSC478-Fall2020/blob/master/data/weather.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data into variable `df` using `pandas.read_csv` like you did above for binary classification.\n",
    "Notice that missing values in this dataset are indicated by the string `'***'`. This should be specified using `na_values` argument of `read_csv`. You must check if there are missing values using DataFrame `.isna().sum()` and drop them using DataFrame `.dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "df = ...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "# Check if there are na's in df\n",
    "...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "# Drop na\n",
    "...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "# Now, check again if there is any more na values left\n",
    "...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check df columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a linear model that predicts the next day's average temperature `tave` from the previous day's values of:\n",
    "1. tave: average temperature\n",
    "2. tmax: maximum temperature\n",
    "3. tmin: minimum temperature\n",
    "4. vp: vapor pressure\n",
    "5. rhmax: maximum relative humidity\n",
    "6. rhmin: minimum relative humidity\n",
    "7. pp: precipitation\n",
    "8. gust: wind gust speed\n",
    "\n",
    "As a hint on how to do this, here is a list with these column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names\n",
    "Xnames = ['tave', 'tmax', 'tmin', 'vp', 'rhmax', 'rhmin', 'pp', 'gust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Required Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "# Select those eight columns in Xnames from df and convert the result to a numpy array - Hint: use .values\n",
    "data = ...\n",
    "\n",
    "# Assign X to be all columns and all but the last row - Hint: Review slicing notebook\n",
    "X = ...\n",
    "\n",
    "# Assign T to be just the first column (tave) and all but the first sample/row.\n",
    "T = ...\n",
    "### END CODING HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So now the first row (sample) in `X` is associated with the first row (sample) in `T` which is tave for the following day. Next, train the model. Run it several times with different `learning_rate` and `n_epochs` values to produce decreasing errors, or at least with an RMSE of less than 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODING HERE ### \n",
    "\n",
    "# Use the function train to train a model for the X and T data.\n",
    "# Try different values for learning_rate and n_epochs\n",
    "model = ...\n",
    "\n",
    "# Use the use function\n",
    "Y = ...\n",
    "### END CODING HERE ###\n",
    "\n",
    "plt.clf()\n",
    "# Plot T versus predicted Y values to show how well the model is working\n",
    "plt.plot(T)\n",
    "plt.plot(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T[100:120], '-o')\n",
    "plt.plot(Y[100:120], '-o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Print the weight values in the resulting model along with their corresponding variable names in `Xnames`. Use the relative magnitude of the weight values to discuss which input variables are most significant in predicting the changes in the tave values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Xnames)):\n",
    "    print(f\"{Xnames[i]:6} {model['w'][i,0]:9.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anser the following question:\n",
    "\n",
    "- Q4 [5 points] Whcih features (input variables) are most significant in predicting the changes in the tave values? Name top three. \n",
    "\n",
    "<font color=red>Enter your answer in the following markdown cell.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your answers to Part III question go HERE below this line:\n",
    "\n",
    "========================================================\n",
    "\n",
    "\n",
    "YOUR Answer:\n",
    "\n",
    "- Q4: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Assignment-1 has a maximum of 100 points. Make sure that you get the correct outputs for all cells that you implement and give complete answers to all questions. Also, your notebook should be written with no grammatical and spelling errors and should be easy-to-read.\n",
    "\n",
    "The breakdown of the 100 points is as follows:\n",
    "\n",
    "- Part I - 35 points\n",
    "    - 30 points: Implementaion and correct outputs - breakdown as follows:\n",
    "        - 20 points: classifiers, training, testing and model evaluation.\n",
    "        - 10 points: correct plot of 2 ROC for 2 classifiers in one plot with different colors.\n",
    "\n",
    "    - 5 points: Part I questions \n",
    "\n",
    "\n",
    "- Part II - 5 points\n",
    "    - normal equation and correct outputs\n",
    "\n",
    "\n",
    "- Part III - 60 points\n",
    "    - 55 points: implementation\n",
    "    - 5 points: Part III question\n",
    "\n",
    "<b>Note: </b>Follow the instructions of each section carefully. Up to 10 points may be deducted if your submitted notebook is not easy to read and follow or if it has grammatical, spelling or formatting issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name your notebook ```Lastname-A1.ipynb```. So, for me it would be `Vafaei-A1.ipynb`. Submit the completed notebook using the ```Assignment-1``` link on Blackboard.\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct implementation, correct answer to the questions, and\n",
    "  * readability of the notebook.\n",
    "  \n",
    "<font color=red><b>Due Date: Monday October 5th, 11:59PM.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "\n",
    "Special thanks to Professor Chuck Anderson from Colorado State University."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
